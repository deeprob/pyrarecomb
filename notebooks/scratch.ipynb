{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori, association_rules\n",
    "from functools import reduce\n",
    "from scipy.stats import binomtest\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from statsmodels.stats.power import tt_ind_solve_power\n",
    "from statsmodels.stats.proportion import proportion_effectsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the input df\n",
    "# boolean_input_df = pd.read_csv(\"/data6/deepro/computational_pipelines/pyrarecomb/test/input/test_input.csv\")\n",
    "# # define all other params\n",
    "# combo_length = 2\n",
    "# min_indv_threshold = 5\n",
    "# max_freq_threshold = 0.25\n",
    "# input_format = 'Input_'\n",
    "# output_format = 'Output_'\n",
    "# pval_filter_threshold = 0.05\n",
    "# adj_pval_type = 'BH'\n",
    "# min_power_threshold = 0.7\n",
    "# sample_names_ind = 'Y'\n",
    "\n",
    "# load the input df\n",
    "boolean_input_df = pd.read_csv(\"/data6/deepro/computational_pipelines/pyrarecomb/test/input/test_input.csv\")\n",
    "primary_inputs = pd.read_csv(\"/data6/deepro/computational_pipelines/pyrarecomb/test/input/primary.txt\", header=None).iloc[:, 0].values\n",
    "# define all other params\n",
    "combo_length = 2\n",
    "min_indv_threshold = 5\n",
    "max_freq_threshold = 0.25\n",
    "input_format = 'Input_'\n",
    "output_format = 'Output_'\n",
    "pval_filter_threshold = 0.05\n",
    "adj_pval_type = 'BH'\n",
    "min_power_threshold = 0.7\n",
    "sample_names_ind = 'Y'\n",
    "primary_input_entities= primary_inputs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of cases remaining after filtration: 2488\n",
      "Number of controls remaining after filtration: 2512\n",
      "Number of items remaining after filtration: 334\n",
      "Number of secondary items remaining after filtration: 299\n",
      "Number of primary items remaining after filtration: 35\n"
     ]
    }
   ],
   "source": [
    "##########\n",
    "# Filter #\n",
    "##########\n",
    "\n",
    "def preprocess_boolean(boolean_input_df, input_format, output_format, min_indv_threshold, max_freq_threshold):\n",
    "    \"\"\"\n",
    "    This function parses and filters user-given boolean dataframe to rarecomb\n",
    "    1) It defines input and output columns\n",
    "    2) It creates case and control boolean matrix for data mining algorithm\n",
    "    3) It filters the matrix to only keep relevant items based on user defined conditions\n",
    "    \"\"\"\n",
    "    # Identify all the input and output variables\n",
    "    input_colname_list = [col for col in boolean_input_df.columns if col.startswith(input_format)]\n",
    "    output_column = [col for col in boolean_input_df.columns if col.startswith(output_format)][0]\n",
    "    # Make cases and controls apriori input df\n",
    "    apriori_input_cases_df = boolean_input_df.loc[boolean_input_df[output_column]==1, input_colname_list].applymap(int)\n",
    "    apriori_input_controls_df = boolean_input_df.loc[boolean_input_df[output_column]==0, input_colname_list].applymap(int)\n",
    "    # Get the number of cases from input param - max freq thresh\n",
    "    number_of_cases = apriori_input_cases_df.shape[0]\n",
    "    max_instances = round(number_of_cases * max_freq_threshold)\n",
    "    # Filter case and control df to only include gene cols that satisfy input criterion\n",
    "    apriori_input_cases_df = apriori_input_cases_df.loc[:, (apriori_input_cases_df.sum() >= min_indv_threshold) \n",
    "                                                        & (apriori_input_controls_df.sum() >= 1) & (apriori_input_cases_df.sum() < max_instances)]\n",
    "    apriori_input_controls_df = apriori_input_controls_df.loc[:, (apriori_input_cases_df.sum() >= min_indv_threshold) \n",
    "                                                              & (apriori_input_controls_df.sum() >= 1) & (apriori_input_cases_df.sum() < max_instances)]\n",
    "    # Select columns that remain\n",
    "    sel_input_colname_list = [col for col in apriori_input_cases_df.columns if col.startswith(input_format)]\n",
    "    return apriori_input_cases_df, apriori_input_controls_df, sel_input_colname_list, output_column, number_of_cases \n",
    "\n",
    "\n",
    "apriori_input_cases_df, apriori_input_controls_df, sel_input_colname_list, output_column, number_of_cases = preprocess_boolean(\n",
    "    boolean_input_df, input_format, output_format, min_indv_threshold, max_freq_threshold\n",
    ")\n",
    "input_colname_only_list = list(set(sel_input_colname_list).difference(set(primary_input_entities)))\n",
    "primary_input_list = list(set(sel_input_colname_list).intersection(set(primary_input_entities)))\n",
    "# debugging\n",
    "print(f\"Number of cases remaining after filtration: {len(apriori_input_cases_df)}\")\n",
    "print(f\"Number of controls remaining after filtration: {len(apriori_input_controls_df)}\")\n",
    "print(f\"Number of items remaining after filtration: {len(sel_input_colname_list)}\")\n",
    "print(f\"Number of secondary items remaining after filtration: {len(input_colname_only_list)}\")\n",
    "print(f\"Number of primary items remaining after filtration: {len(primary_input_list)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_freq_items_combo(frequent_itemsets, combo_length):\n",
    "    # get items of specific combo size\n",
    "    frequent_itemsets = frequent_itemsets.loc[frequent_itemsets.length==combo_length].drop(columns=[\"length\"])\n",
    "    # Split itemsets into separate columns\n",
    "    frequent_itemsets = frequent_itemsets.merge(frequent_itemsets['itemsets'].apply(lambda x: pd.Series(list(x))), left_index=True, right_index=True).drop(columns=[\"support\", \"itemsets\"])\n",
    "    # rename columns\n",
    "    old_colnames = range(combo_length)\n",
    "    new_colnames = [f\"Item_{i}\" for i in range(1, combo_length+1)]\n",
    "    frequent_itemsets = frequent_itemsets.rename(columns=dict(zip(old_colnames, new_colnames)))\n",
    "    return frequent_itemsets.loc[:, new_colnames + [\"uniq_items\", \"Obs_Count_Combo\"]].reset_index(drop=True)\n",
    "\n",
    "def add_frozensets(a, b):\n",
    "    return a.union(b)  \n",
    "\n",
    "def run_apriori_freqitems(apriori_input_df, combo_length, support_threshold, primary_entities=None):\n",
    "    frequent_itemsets = apriori(\n",
    "        apriori_input_df.astype(bool), min_support=support_threshold, \n",
    "        use_colnames=True, max_len=combo_length\n",
    "        )\n",
    "    if primary_entities is not None:\n",
    "        # run association rules\n",
    "        assoc_df = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.0)\n",
    "        # the primary entities must be in the consequents only\n",
    "        assoc_df = assoc_df.loc[\n",
    "            (assoc_df.consequents.apply(lambda x: True if len(x.intersection(primary_entities))>0 else False)) &\n",
    "            (assoc_df.antecedents.apply(lambda x: True if len(x.intersection(primary_entities))==0 else False))\n",
    "            ]\n",
    "        # convert assoc df to frequent items\n",
    "        assoc_df[\"itemsets\"] = assoc_df.apply(lambda row: row[\"antecedents\"].union(row[\"consequents\"]), axis=1)\n",
    "        # get the individual items from frequent items\n",
    "        frequent_itemsets = frequent_itemsets.loc[frequent_itemsets.itemsets.apply(lambda x: len(x)==1)]\n",
    "        # add the filtered items obtained from association mining\n",
    "        frequent_itemsets = pd.concat((frequent_itemsets, assoc_df.loc[:, [\"itemsets\", \"support\"]]))\n",
    "\n",
    "    frequent_itemsets['count'] = frequent_itemsets['support'] * len(apriori_input_df)\n",
    "    frequent_itemsets['Obs_Count_Combo'] = frequent_itemsets.pop('count')\n",
    "    frequent_itemsets['length'] = frequent_itemsets['itemsets'].apply(lambda x: len(x))\n",
    "    frequent_itemsets['uniq_items'] = frequent_itemsets['itemsets'].apply(lambda x: \"|\".join(sorted(x)))\n",
    "    frequent_itemsets_len_combo = get_freq_items_combo(frequent_itemsets, combo_length)\n",
    "    frequent_itemsets_len_1 = get_freq_items_combo(frequent_itemsets, 1)\n",
    "    return frequent_itemsets_len_combo, frequent_itemsets_len_1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of initial combinations identified for cases: 24\n",
      "Number of unique items in cases: 28\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "# CASES / SEVERE Phenotype #\n",
    "############################################################################################################\n",
    "# APRIORI (Combo): Generate frequent itemset of a given size in which mutations/events co-occur among them #\n",
    "############################################################################################################\n",
    "# Introduce a support threshold\n",
    "support_threshold = min_indv_threshold / apriori_input_cases_df.shape[0]\n",
    "case_freqitems_df, case_freqitems_size1_df = run_apriori_freqitems(apriori_input_cases_df, combo_length, support_threshold, primary_entities=primary_input_list)\n",
    "# set the number of frequent items column name \n",
    "case_freqitems_df = case_freqitems_df.rename(columns={\"Obs_Count_Combo\": \"Case_Obs_Count_Combo\"})\n",
    "# get the number of unique items forming combinations\n",
    "uniq_combo_items = set(case_freqitems_df.loc[:, [f\"Item_{i}\" for i in range(1, combo_length+1)]].values.flatten())\n",
    "# Store the counts as a dictionary for each item\n",
    "case_freqitems_countdict = dict(zip(case_freqitems_size1_df.Item_1, case_freqitems_size1_df.Obs_Count_Combo.astype(int)))\n",
    "# Get the observed count for each item\n",
    "for i in range(1, combo_length+1):\n",
    "    case_freqitems_df[f\"Case_Obs_Count_I{i}\"] = case_freqitems_df[f\"Item_{i}\"].map(case_freqitems_countdict)\n",
    "# Get the expected probability of observing the combos\n",
    "case_freqitems_df[\"Case_Exp_Prob_Combo\"] = case_freqitems_df.loc[:, [f\"Case_Obs_Count_I{i}\" for i in range(1, combo_length+1)]].prod(axis=1)/(number_of_cases**combo_length)\n",
    "# Get the observed probability of observing the combos\n",
    "case_freqitems_df['Case_Obs_Prob_Combo'] = case_freqitems_df['Case_Obs_Count_Combo'] / number_of_cases\n",
    "# Using bionomial test, calculate p-value\n",
    "case_freqitems_df['Case_pvalue_more'] = case_freqitems_df.apply(lambda row: binomtest(int(row['Case_Obs_Count_Combo']), number_of_cases, row['Case_Exp_Prob_Combo'], alternative='greater').pvalue, axis=1)\n",
    "# debugging\n",
    "print(f'Number of initial combinations identified for cases: {case_freqitems_df.shape[0]}')\n",
    "print(f'Number of unique items in cases: {len(uniq_combo_items)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of controls: 2512\n",
      "Number of combinations with support of at least 2 in controls: 92\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# CONTROLS / MILD Phenotype #\n",
    "#############################\n",
    "# Get the control profile of the combo items\n",
    "apriori_input_controls_df = apriori_input_controls_df.loc[:, list(uniq_combo_items)]\n",
    "number_of_controls = apriori_input_controls_df.shape[0]\n",
    "# define support threshold for controls\n",
    "support_threshold = 2 / number_of_controls\n",
    "# get the frequently mutated genes in controls using apriori\n",
    "sel_primary_input_list = uniq_combo_items.intersection(primary_input_list)\n",
    "cont_freqitems_df, cont_freqitems_size1_df = run_apriori_freqitems(apriori_input_controls_df, combo_length, support_threshold, primary_entities=sel_primary_input_list)\n",
    "# set the number of frequent items column name \n",
    "cont_freqitems_df = cont_freqitems_df.rename(columns={\"Obs_Count_Combo\": \"Cont_Obs_Count_Combo\"})\n",
    "# Store the counts as a dictionary for each item\n",
    "cont_freqitems_countdict = dict(zip(cont_freqitems_size1_df.Item_1, cont_freqitems_size1_df.Obs_Count_Combo.astype(int)))\n",
    "# Keep combos found in case only\n",
    "case_cont_freqitems_df = case_freqitems_df.merge(cont_freqitems_df, left_on=\"uniq_items\", right_on=\"uniq_items\", how=\"left\", suffixes=('', '_cont')).drop(columns=[f\"Item_{i}_cont\" for i in range(1, combo_length + 1)]).fillna(0.)\n",
    "# Get the observed count in controls for each item\n",
    "for i in range(1, combo_length+1):\n",
    "    case_cont_freqitems_df[f\"Cont_Obs_Count_I{i}\"] = case_cont_freqitems_df[f\"Item_{i}\"].map(cont_freqitems_countdict)\n",
    "# Get the expected probability of observing the combos in controls\n",
    "case_cont_freqitems_df[\"Cont_Exp_Prob_Combo\"] = case_cont_freqitems_df.loc[:, [f\"Cont_Obs_Count_I{i}\" for i in range(1, combo_length+1)]].prod(axis=1)/(number_of_controls**combo_length)\n",
    "# Get the observed probability of observing the combos\n",
    "case_cont_freqitems_df['Cont_Obs_Prob_Combo'] = case_cont_freqitems_df['Cont_Obs_Count_Combo'] / number_of_controls\n",
    "# Using bionomial test, calculate p-value\n",
    "case_cont_freqitems_df['Cont_pvalue_more'] = case_cont_freqitems_df.apply(lambda row: binomtest(int(row['Cont_Obs_Count_Combo']), number_of_controls, row['Cont_Exp_Prob_Combo'], alternative='greater').pvalue, axis=1)\n",
    "# debugging\n",
    "print(f\"Number of controls: {number_of_controls}\")\n",
    "print(f\"Number of combinations with support of at least 2 in controls: {cont_freqitems_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations considered for multiple testing correction: 24\n",
      "Number of combinations that are significant after multiple testing correction: 4\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "# Nominal significance #\n",
    "########################\n",
    "# TODO: This step is not omitted from compare_enrichment_depletion since we\n",
    "# TODO: consider all for multiple testing.\n",
    "sel_case_cont_freqitems_df = case_cont_freqitems_df\n",
    "# debugging\n",
    "print(f\"Number of combinations considered for multiple testing correction: {sel_case_cont_freqitems_df.shape[0]}\")\n",
    "\n",
    "####################\n",
    "# Multiple testing #\n",
    "####################\n",
    "# Create variable for number of tests done\n",
    "number_of_tests = sel_case_cont_freqitems_df.shape[0]\n",
    "# multiple test BH and Bonferroni\n",
    "sel_case_cont_freqitems_df['Case_Adj_Pval_bonf'] = np.round(multipletests(sel_case_cont_freqitems_df['Case_pvalue_more'].values, method='bonferroni')[1], 3)\n",
    "sel_case_cont_freqitems_df['Case_Adj_Pval_BH'] = np.round(multipletests(sel_case_cont_freqitems_df['Case_pvalue_more'].values, method='fdr_bh')[1], 3)\n",
    "# add a column for number of tests done\n",
    "sel_case_cont_freqitems_df['Num_tests'] = number_of_tests\n",
    "# filter significant items\n",
    "if adj_pval_type == 'BH':\n",
    "    all_sig_case_cont_freqitems_df = sel_case_cont_freqitems_df[\n",
    "        (sel_case_cont_freqitems_df['Case_Adj_Pval_BH'] < pval_filter_threshold) &\n",
    "        (sel_case_cont_freqitems_df['Cont_pvalue_more'] > pval_filter_threshold)\n",
    "    ]\n",
    "elif adj_pval_type == 'bonferroni':\n",
    "    all_sig_case_cont_freqitems_df = sel_case_cont_freqitems_df[\n",
    "        (sel_case_cont_freqitems_df['Case_Adj_Pval_bonf'] < pval_filter_threshold) &\n",
    "        (sel_case_cont_freqitems_df['Cont_pvalue_more'] > pval_filter_threshold)\n",
    "    ]\n",
    "multtest_sig_comb_count = all_sig_case_cont_freqitems_df.shape[0]\n",
    "# debugging\n",
    "print(f\"Number of combinations that are significant after multiple testing correction: {multtest_sig_comb_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_counts(uniq_items, input_df):\n",
    "    \"\"\"\n",
    "    This function gets the counts of combos from an input boolean df\n",
    "    \"\"\"\n",
    "    query = \" & \".join([f\"({i} == 1)\" for i in uniq_items.split(\"|\")])\n",
    "    return len(input_df.query(query))\n",
    "\n",
    "def refine_control_frequencies(all_sig_case_cont_freqitems_df, apriori_input_controls_df,number_of_controls,check_enrichment=True):\n",
    "    # Check if zero frequency cases exist in controls\n",
    "    cont_combos_w_zero_freq_df = all_sig_case_cont_freqitems_df.loc[all_sig_case_cont_freqitems_df[\"Cont_Obs_Count_Combo\"] == 0]\n",
    "    zero_freq_combo_count = cont_combos_w_zero_freq_df.shape[0]\n",
    "    print('Number of combinations with support less than 2 in controls:', zero_freq_combo_count)\n",
    "    if zero_freq_combo_count > 0:\n",
    "        # REFINE CONTROL FREQUENCIES\n",
    "        # for the zero frequency combos in controls, get their actual combo size\n",
    "        cont_combos_w_zero_freq_df[\"Cont_Obs_Count_Combo\"] = cont_combos_w_zero_freq_df.uniq_items.apply(get_counts, args=(apriori_input_controls_df, ))\n",
    "        cont_combos_w_zero_freq_df[\"Cont_Obs_Prob_Combo\"] = cont_combos_w_zero_freq_df['Cont_Obs_Count_Combo'] / number_of_controls\n",
    "        if check_enrichment:\n",
    "            cont_combos_w_zero_freq_df['Cont_pvalue_more'] = cont_combos_w_zero_freq_df.apply(lambda row: binomtest(int(row['Cont_Obs_Count_Combo']), number_of_controls, row['Cont_Exp_Prob_Combo'], alternative='greater').pvalue, axis=1)\n",
    "        else:\n",
    "            # check for depletion\n",
    "            cont_combos_w_zero_freq_df['Cont_pvalue_less'] = cont_combos_w_zero_freq_df.apply(lambda row: binomtest(int(row['Cont_Obs_Count_Combo']), number_of_controls, row['Cont_Exp_Prob_Combo'], alternative='less').pvalue, axis=1)\n",
    "        # rewrite the items in the main df\n",
    "        all_sig_case_cont_freqitems_df.update(cont_combos_w_zero_freq_df)\n",
    "    return all_sig_case_cont_freqitems_df\n",
    "\n",
    "def calculate_power(all_sig_case_cont_freqitems_df, number_of_cases, number_of_controls):\n",
    "    all_sig_case_cont_freqitems_df['Case_Exp_Count_Combo'] = round((all_sig_case_cont_freqitems_df['Case_Exp_Prob_Combo'] * number_of_cases), 2)\n",
    "    all_sig_case_cont_freqitems_df['Cont_Exp_Count_Combo'] = round((all_sig_case_cont_freqitems_df['Cont_Exp_Prob_Combo'] * number_of_controls), 2)\n",
    "    all_sig_case_cont_freqitems_df['Effect_Size'] = all_sig_case_cont_freqitems_df.apply(\n",
    "        lambda row: proportion_effectsize(row['Case_Obs_Prob_Combo'], row['Cont_Obs_Prob_Combo']), axis=1)\n",
    "    all_sig_case_cont_freqitems_df['Power_One_Pct'] = round(all_sig_case_cont_freqitems_df.apply(\n",
    "        lambda row: tt_ind_solve_power(effect_size=row['Effect_Size'], nobs1=number_of_cases, ratio=number_of_controls/number_of_cases, alpha=0.01), axis=1), 3)\n",
    "    all_sig_case_cont_freqitems_df['Power_Five_Pct'] = round(all_sig_case_cont_freqitems_df.apply(\n",
    "        lambda row: tt_ind_solve_power(effect_size=row['Effect_Size'], nobs1=number_of_cases, ratio=number_of_controls/number_of_cases, alpha=0.05),axis=1), 3)\n",
    "    return all_sig_case_cont_freqitems_df\n",
    "\n",
    "def get_samples(row, samples_df, output_column):\n",
    "    \"\"\"\n",
    "    Helper function for adding sample information\n",
    "    \"\"\"\n",
    "    items = row.uniq_items.split(\"|\")\n",
    "    count_cases = Counter(samples_df.loc[(samples_df.Items.isin(items))&(samples_df[output_column]==1)].Sample_Name)\n",
    "    case_samples = [s for s,ns in count_cases.items() if ns==len(items)]\n",
    "    count_controls = Counter(samples_df.loc[(samples_df.Items.isin(items))&(samples_df[output_column]==0)].Sample_Name)\n",
    "    control_samples = [s for s,ns in count_controls.items() if ns==len(items)]\n",
    "    return pd.Series({\"Case_Samples\": \"|\".join(case_samples), \"Control_Samples\": \"|\".join(control_samples)})\n",
    "\n",
    "def add_sample_info(boolean_input_df, output_sig_case_cont_freqitems_df, output_column):\n",
    "    # add case and control samples for each combo\n",
    "    samples_df = boolean_input_df.set_index([\"Sample_Name\", output_column])\n",
    "    samples_df = samples_df.mask(samples_df == 0).stack().reset_index().drop(0, axis=1).rename(columns={\"level_2\": \"Items\"})\n",
    "    output_sig_case_cont_freqitems_df = output_sig_case_cont_freqitems_df.merge(output_sig_case_cont_freqitems_df.apply(get_samples, args=(samples_df, output_column), axis=1), left_index=True, right_index=True)\n",
    "    return output_sig_case_cont_freqitems_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations with support less than 2 in controls: 1\n",
      "Number of significant combinations that meet the power threshold is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_14193/2212866994.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cont_combos_w_zero_freq_df[\"Cont_Obs_Count_Combo\"] = cont_combos_w_zero_freq_df.uniq_items.apply(get_counts, args=(apriori_input_controls_df, ))\n",
      "/tmp/ipykernel_14193/2212866994.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cont_combos_w_zero_freq_df[\"Cont_Obs_Prob_Combo\"] = cont_combos_w_zero_freq_df['Cont_Obs_Count_Combo'] / number_of_controls\n",
      "/tmp/ipykernel_14193/2212866994.py:19: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cont_combos_w_zero_freq_df['Cont_pvalue_more'] = cont_combos_w_zero_freq_df.apply(lambda row: binomtest(int(row['Cont_Obs_Count_Combo']), number_of_controls, row['Cont_Exp_Prob_Combo'], alternative='greater').pvalue, axis=1)\n",
      "/tmp/ipykernel_14193/2212866994.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_sig_case_cont_freqitems_df['Case_Exp_Count_Combo'] = round((all_sig_case_cont_freqitems_df['Case_Exp_Prob_Combo'] * number_of_cases), 2)\n",
      "/tmp/ipykernel_14193/2212866994.py:29: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_sig_case_cont_freqitems_df['Cont_Exp_Count_Combo'] = round((all_sig_case_cont_freqitems_df['Cont_Exp_Prob_Combo'] * number_of_controls), 2)\n",
      "/tmp/ipykernel_14193/2212866994.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_sig_case_cont_freqitems_df['Effect_Size'] = all_sig_case_cont_freqitems_df.apply(\n",
      "/tmp/ipykernel_14193/2212866994.py:32: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_sig_case_cont_freqitems_df['Power_One_Pct'] = round(all_sig_case_cont_freqitems_df.apply(\n",
      "/tmp/ipykernel_14193/2212866994.py:34: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_sig_case_cont_freqitems_df['Power_Five_Pct'] = round(all_sig_case_cont_freqitems_df.apply(\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# Post processing #\n",
    "###################\n",
    "# Check if there is at least a single significant combination after multiple testing correction\n",
    "if multtest_sig_comb_count > 0:\n",
    "    # TODO: Refining control frequencies may not be required if support is changed to 1/num_controls for combos\n",
    "    all_sig_case_cont_freqitems_df = refine_control_frequencies(all_sig_case_cont_freqitems_df, apriori_input_controls_df,number_of_controls)\n",
    "\n",
    "    ######################\n",
    "    # POWER CALCULATIONS #\n",
    "    ######################\n",
    "    all_sig_case_cont_freqitems_df = calculate_power(all_sig_case_cont_freqitems_df, number_of_cases, number_of_controls)\n",
    "    output_sig_case_cont_freqitems_df = all_sig_case_cont_freqitems_df.loc[all_sig_case_cont_freqitems_df.Power_Five_Pct >= min_power_threshold]\n",
    "    \n",
    "    #####################\n",
    "    # SAMPLES DETECTION #\n",
    "    #####################\n",
    "    if len(output_sig_case_cont_freqitems_df)>0:\n",
    "        print(f\"Number of significant combinations that meet the power threshold is {len(output_sig_case_cont_freqitems_df)}\")\n",
    "        if sample_names_ind == \"Y\":\n",
    "            output_sig_case_cont_freqitems_df = add_sample_info(boolean_input_df, output_sig_case_cont_freqitems_df, output_column)\n",
    "\n",
    "    \n",
    "    else:\n",
    "        print(\"No significant combinations that meet the specified power threshold\")\n",
    "        print(\"Returning ONLY the non-significant combinations\")\n",
    "        output_sig_case_cont_freqitems_df = sel_case_cont_freqitems_df\n",
    "\n",
    "else:\n",
    "    print(\"No significant combinations were found after multiple testing correction\")\n",
    "    print(\"Returning ONLY the non-significant combinations\")\n",
    "    output_sig_case_cont_freqitems_df = sel_case_cont_freqitems_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_1</th>\n",
       "      <th>Item_2</th>\n",
       "      <th>uniq_items</th>\n",
       "      <th>Case_Obs_Count_Combo</th>\n",
       "      <th>Case_Obs_Count_I1</th>\n",
       "      <th>Case_Obs_Count_I2</th>\n",
       "      <th>Case_Exp_Prob_Combo</th>\n",
       "      <th>Case_Obs_Prob_Combo</th>\n",
       "      <th>Case_pvalue_more</th>\n",
       "      <th>Cont_Obs_Count_Combo</th>\n",
       "      <th>...</th>\n",
       "      <th>Cont_Obs_Prob_Combo</th>\n",
       "      <th>Cont_pvalue_more</th>\n",
       "      <th>Case_Adj_Pval_bonf</th>\n",
       "      <th>Case_Adj_Pval_BH</th>\n",
       "      <th>Num_tests</th>\n",
       "      <th>Case_Exp_Count_Combo</th>\n",
       "      <th>Cont_Exp_Count_Combo</th>\n",
       "      <th>Effect_Size</th>\n",
       "      <th>Power_One_Pct</th>\n",
       "      <th>Power_Five_Pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Input_7</td>\n",
       "      <td>Input_65</td>\n",
       "      <td>Input_65|Input_7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>28</td>\n",
       "      <td>80</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>3.426543e-04</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001194</td>\n",
       "      <td>0.119919</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.003</td>\n",
       "      <td>24</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.029125</td>\n",
       "      <td>0.061</td>\n",
       "      <td>0.177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Input_46</td>\n",
       "      <td>Input_158</td>\n",
       "      <td>Input_158|Input_46</td>\n",
       "      <td>5.0</td>\n",
       "      <td>47</td>\n",
       "      <td>36</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>6.890116e-04</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000796</td>\n",
       "      <td>0.170247</td>\n",
       "      <td>0.017</td>\n",
       "      <td>0.004</td>\n",
       "      <td>24</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.033247</td>\n",
       "      <td>0.081</td>\n",
       "      <td>0.217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Input_353</td>\n",
       "      <td>Input_55</td>\n",
       "      <td>Input_353|Input_55</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>1.060869e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>24</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.089688</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Input_445</td>\n",
       "      <td>Input_462</td>\n",
       "      <td>Input_445|Input_462</td>\n",
       "      <td>7.0</td>\n",
       "      <td>74</td>\n",
       "      <td>73</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>6.943866e-03</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001592</td>\n",
       "      <td>0.082795</td>\n",
       "      <td>0.167</td>\n",
       "      <td>0.028</td>\n",
       "      <td>24</td>\n",
       "      <td>2.17</td>\n",
       "      <td>1.63</td>\n",
       "      <td>0.026305</td>\n",
       "      <td>0.050</td>\n",
       "      <td>0.153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Item_1     Item_2           uniq_items  Case_Obs_Count_Combo  \\\n",
       "0     Input_7   Input_65     Input_65|Input_7                   6.0   \n",
       "4    Input_46  Input_158   Input_158|Input_46                   5.0   \n",
       "5   Input_353   Input_55   Input_353|Input_55                   5.0   \n",
       "22  Input_445  Input_462  Input_445|Input_462                   7.0   \n",
       "\n",
       "    Case_Obs_Count_I1  Case_Obs_Count_I2  Case_Exp_Prob_Combo  \\\n",
       "0                  28                 80             0.000362   \n",
       "4                  47                 36             0.000273   \n",
       "5                  14                 19             0.000043   \n",
       "22                 74                 73             0.000873   \n",
       "\n",
       "    Case_Obs_Prob_Combo  Case_pvalue_more  Cont_Obs_Count_Combo  ...  \\\n",
       "0              0.002412      3.426543e-04                   3.0  ...   \n",
       "4              0.002010      6.890116e-04                   2.0  ...   \n",
       "5              0.002010      1.060869e-07                   0.0  ...   \n",
       "22             0.002814      6.943866e-03                   4.0  ...   \n",
       "\n",
       "    Cont_Obs_Prob_Combo  Cont_pvalue_more  Case_Adj_Pval_bonf  \\\n",
       "0              0.001194          0.119919               0.008   \n",
       "4              0.000796          0.170247               0.017   \n",
       "5              0.000000          1.000000               0.000   \n",
       "22             0.001592          0.082795               0.167   \n",
       "\n",
       "    Case_Adj_Pval_BH  Num_tests  Case_Exp_Count_Combo  Cont_Exp_Count_Combo  \\\n",
       "0              0.003         24                  0.90                  1.20   \n",
       "4              0.004         24                  0.68                  0.74   \n",
       "5              0.000         24                  0.11                  0.07   \n",
       "22             0.028         24                  2.17                  1.63   \n",
       "\n",
       "    Effect_Size  Power_One_Pct  Power_Five_Pct  \n",
       "0      0.029125          0.061           0.177  \n",
       "4      0.033247          0.081           0.217  \n",
       "5      0.089688          0.724           0.887  \n",
       "22     0.026305          0.050           0.153  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_sig_case_cont_freqitems_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_1</th>\n",
       "      <th>Item_2</th>\n",
       "      <th>uniq_items</th>\n",
       "      <th>Case_Obs_Count_Combo</th>\n",
       "      <th>Case_Obs_Count_I1</th>\n",
       "      <th>Case_Obs_Count_I2</th>\n",
       "      <th>Case_Exp_Prob_Combo</th>\n",
       "      <th>Case_Obs_Prob_Combo</th>\n",
       "      <th>Case_pvalue_more</th>\n",
       "      <th>Cont_Obs_Count_Combo</th>\n",
       "      <th>...</th>\n",
       "      <th>Case_Adj_Pval_bonf</th>\n",
       "      <th>Case_Adj_Pval_BH</th>\n",
       "      <th>Num_tests</th>\n",
       "      <th>Case_Exp_Count_Combo</th>\n",
       "      <th>Cont_Exp_Count_Combo</th>\n",
       "      <th>Effect_Size</th>\n",
       "      <th>Power_One_Pct</th>\n",
       "      <th>Power_Five_Pct</th>\n",
       "      <th>Case_Samples</th>\n",
       "      <th>Control_Samples</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Input_353</td>\n",
       "      <td>Input_55</td>\n",
       "      <td>Input_353|Input_55</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.00201</td>\n",
       "      <td>1.060869e-07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.089688</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.887</td>\n",
       "      <td>Sample_1425|Sample_2118|Sample_2284|Sample_403...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Item_1    Item_2          uniq_items  Case_Obs_Count_Combo  \\\n",
       "5  Input_353  Input_55  Input_353|Input_55                   5.0   \n",
       "\n",
       "   Case_Obs_Count_I1  Case_Obs_Count_I2  Case_Exp_Prob_Combo  \\\n",
       "5                 14                 19             0.000043   \n",
       "\n",
       "   Case_Obs_Prob_Combo  Case_pvalue_more  Cont_Obs_Count_Combo  ...  \\\n",
       "5              0.00201      1.060869e-07                   0.0  ...   \n",
       "\n",
       "   Case_Adj_Pval_bonf  Case_Adj_Pval_BH  Num_tests  Case_Exp_Count_Combo  \\\n",
       "5                 0.0               0.0         24                  0.11   \n",
       "\n",
       "   Cont_Exp_Count_Combo  Effect_Size  Power_One_Pct  Power_Five_Pct  \\\n",
       "5                  0.07     0.089688          0.724           0.887   \n",
       "\n",
       "                                        Case_Samples  Control_Samples  \n",
       "5  Sample_1425|Sample_2118|Sample_2284|Sample_403...                   \n",
       "\n",
       "[1 rows x 25 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sig_case_cont_freqitems_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################################\n",
    "# APRIORI (Individual): Generate frequencies of event for each individual entity #\n",
    "##################################################################################\n",
    "support_threshold = min_indv_threshold / apriori_input_cases_df.shape[0]\n",
    "include_output_ind = \"N\"\n",
    "# get the frequency of mutations for individual genes using apriori\n",
    "case_freqitems_size1_df = run_apriori_freqitems(apriori_input_cases_df, 1, support_threshold, uniq_combo_items, include_output_ind=include_output_ind)\n",
    "# Store the counts as a dictionary for each item\n",
    "case_freqitems_countdict = dict(zip(case_freqitems_size1_df.Item_1, case_freqitems_size1_df.Obs_Count_Combo.astype(int)))\n",
    "# Get the observed count for each item\n",
    "for i in range(1, combo_length+1):\n",
    "    case_freqitems_df[f\"Case_Obs_Count_I{i}\"] = case_freqitems_df[f\"Item_{i}\"].map(case_freqitems_countdict)\n",
    "# Get the expected probability of observing the combos\n",
    "case_freqitems_df[\"Case_Exp_Prob_Combo\"] = case_freqitems_df.loc[:, [f\"Case_Obs_Count_I{i}\" for i in range(1, combo_length+1)]].prod(axis=1)/(number_of_cases**combo_length)\n",
    "# Get the observed probability of observing the combos\n",
    "case_freqitems_df['Case_Obs_Prob_Combo'] = case_freqitems_df['Case_Obs_Count_Combo'] / number_of_cases\n",
    "# Using bionomial test, calculate p-value\n",
    "case_freqitems_df['Case_pvalue_more'] = case_freqitems_df.apply(lambda row: binomtest(int(row['Case_Obs_Count_Combo']), number_of_cases, row['Case_Exp_Prob_Combo'], alternative='greater').pvalue, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of controls: 2512\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations with support of at least 2 in controls: 1357\n"
     ]
    }
   ],
   "source": [
    "#############################\n",
    "# CONTROLS / MILD Phenotype #\n",
    "############################################################################################################\n",
    "# APRIORI (Combo): Generate frequent itemset of a given size in which mutations/events co-occur among them #\n",
    "############################################################################################################\n",
    "# Get the control profile of the combo items\n",
    "apriori_input_controls_df = apriori_input_controls_df.loc[:, list(uniq_combo_items)]\n",
    "number_of_controls = apriori_input_controls_df.shape[0]\n",
    "print(f\"Number of controls: {number_of_controls}\")\n",
    "\n",
    "# define support threshold for controls\n",
    "support_threshold = 2 / number_of_controls\n",
    "include_output_ind = \"N\"\n",
    "\n",
    "# get the frequently mutated genes in controls using apriori\n",
    "cont_freqitems_df = run_apriori_freqitems(apriori_input_controls_df, combo_length, support_threshold, uniq_combo_items, include_output_ind=include_output_ind)\n",
    "# set the number of frequent items column name \n",
    "cont_freqitems_df = cont_freqitems_df.rename(columns={\"Obs_Count_Combo\": \"Cont_Obs_Count_Combo\"})\n",
    "print(f\"Number of combinations with support of at least 2 in controls: {cont_freqitems_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations that are enriched in both cases and controls: 47\n",
      "Number of combinations considered for multiple testing correction: 246\n"
     ]
    }
   ],
   "source": [
    "##################################################################################\n",
    "# APRIORI (Individual): Generate frequencies of event for each individual entity #\n",
    "##################################################################################\n",
    "\n",
    "support_threshold = 1 / apriori_input_controls_df.shape[0]\n",
    "include_output_ind = \"N\"\n",
    "\n",
    "cont_freqitems_size1_df = run_apriori_freqitems(apriori_input_controls_df, 1, support_threshold, uniq_combo_items, include_output_ind=include_output_ind)\n",
    "# Store the counts as a dictionary for each item\n",
    "cont_freqitems_countdict = dict(zip(cont_freqitems_size1_df.Item_1, cont_freqitems_size1_df.Obs_Count_Combo.astype(int)))\n",
    "# Keep combos found in case only\n",
    "case_freqitems_df[\"uniq_items\"] = case_freqitems_df.loc[:, [f\"Item_{i}\" for i in range(1, combo_length + 1)]].apply(lambda x: \"|\".join(sorted(x)), axis=1)\n",
    "cont_freqitems_df[\"uniq_items\"] = cont_freqitems_df.loc[:, [f\"Item_{i}\" for i in range(1, combo_length + 1)]].apply(lambda x: \"|\".join(sorted(x)), axis=1)\n",
    "case_cont_freqitems_df = case_freqitems_df.merge(cont_freqitems_df, left_on=\"uniq_items\", right_on=\"uniq_items\", how=\"left\", suffixes=('', '_cont')).drop(columns=[f\"Item_{i}_cont\" for i in range(1, combo_length + 1)]).fillna(0.)\n",
    "# Get the observed count in controls for each item\n",
    "for i in range(1, combo_length+1):\n",
    "    case_cont_freqitems_df[f\"Cont_Obs_Count_I{i}\"] = case_cont_freqitems_df[f\"Item_{i}\"].map(cont_freqitems_countdict)\n",
    "# Get the expected probability of observing the combos in controls\n",
    "case_cont_freqitems_df[\"Cont_Exp_Prob_Combo\"] = case_cont_freqitems_df.loc[:, [f\"Cont_Obs_Count_I{i}\" for i in range(1, combo_length+1)]].prod(axis=1)/(number_of_controls**combo_length)\n",
    "# Get the observed probability of observing the combos\n",
    "case_cont_freqitems_df['Cont_Obs_Prob_Combo'] = case_cont_freqitems_df['Cont_Obs_Count_Combo'] / number_of_controls\n",
    "# Using bionomial test, calculate p-value\n",
    "case_cont_freqitems_df['Cont_pvalue_more'] = case_cont_freqitems_df.apply(lambda row: binomtest(int(row['Cont_Obs_Count_Combo']), number_of_controls, row['Cont_Exp_Prob_Combo'], alternative='greater').pvalue, axis=1)\n",
    "# get cases where case pvalue and control pvalue are both significant\n",
    "filt_case_cont_freqitems_df = case_cont_freqitems_df.loc[(case_cont_freqitems_df['Case_pvalue_more'] < pval_filter_threshold) &\n",
    "                                                        (case_cont_freqitems_df['Cont_pvalue_more'] < pval_filter_threshold)\n",
    "                                                        ]\n",
    "# get cases where either case pvalue or control pvalue are not significant                   \n",
    "sel_case_cont_freqitems_df = case_cont_freqitems_df.loc[~((case_cont_freqitems_df['Case_pvalue_more'] < pval_filter_threshold) &\n",
    "                                                        (case_cont_freqitems_df['Cont_pvalue_more'] < pval_filter_threshold))\n",
    "                                                        ]\n",
    "# debugging\n",
    "print(f\"Number of combinations that are enriched in both cases and controls: {filt_case_cont_freqitems_df.shape[0]}\")\n",
    "print(f\"Number of combinations considered for multiple testing correction: {sel_case_cont_freqitems_df.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations that are significant after multiple testing correction: 91\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_89739/86612666.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sel_case_cont_freqitems_df['Case_Adj_Pval_bonf'] = multipletests(sel_case_cont_freqitems_df['Case_pvalue_more'].values, method='bonferroni')[1]\n",
      "/tmp/ipykernel_89739/86612666.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sel_case_cont_freqitems_df['Case_Adj_Pval_BH'] = multipletests(sel_case_cont_freqitems_df['Case_pvalue_more'].values, method='fdr_bh')[1]\n"
     ]
    }
   ],
   "source": [
    "####################\n",
    "# Multiple testing #\n",
    "####################\n",
    "\n",
    "# Create variable for number of tests done\n",
    "number_of_tests = sel_case_cont_freqitems_df.shape[0]\n",
    "\n",
    "sel_case_cont_freqitems_df['Case_Adj_Pval_bonf'] = multipletests(sel_case_cont_freqitems_df['Case_pvalue_more'].values, method='bonferroni')[1]\n",
    "sel_case_cont_freqitems_df['Case_Adj_Pval_BH'] = multipletests(sel_case_cont_freqitems_df['Case_pvalue_more'].values, method='fdr_bh')[1]\n",
    "\n",
    "if adj_pval_type == 'BH':\n",
    "    all_sig_case_cont_freqitems_df = sel_case_cont_freqitems_df[\n",
    "        (sel_case_cont_freqitems_df['Case_Adj_Pval_BH'] < pval_filter_threshold) &\n",
    "        (sel_case_cont_freqitems_df['Cont_pvalue_more'] > pval_filter_threshold)\n",
    "    ]\n",
    "elif adj_pval_type == 'bonferroni':\n",
    "    all_sig_case_cont_freqitems_df = sel_case_cont_freqitems_df[\n",
    "        (sel_case_cont_freqitems_df['Case_Adj_Pval_bonf'] < pval_filter_threshold) &\n",
    "        (sel_case_cont_freqitems_df['Cont_pvalue_more'] > pval_filter_threshold)\n",
    "    ]\n",
    "\n",
    "multtest_sig_comb_count = all_sig_case_cont_freqitems_df.shape[0]\n",
    "# debugging\n",
    "print(f\"Number of combinations that are significant after multiple testing correction: {multtest_sig_comb_count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_counts(uniq_items, input_df):\n",
    "    query = \" & \".join([f\"({i} == 1)\" for i in uniq_items.split(\"|\")])\n",
    "    return len(input_df.query(query))\n",
    "\n",
    "def get_samples(row, samples_df, output_column):\n",
    "    items = row.uniq_items.split(\"|\")\n",
    "    count_cases = Counter(samples_df.loc[(samples_df.Items.isin(items))&(samples_df[output_column]==1)].Sample_Name)\n",
    "    case_samples = [s for s,ns in count_cases.items() if ns==len(items)]\n",
    "    count_controls = Counter(samples_df.loc[(samples_df.Items.isin(items))&(samples_df[output_column]==0)].Sample_Name)\n",
    "    control_samples = [s for s,ns in count_controls.items() if ns==len(items)]\n",
    "    return pd.Series({\"Case_Samples\": \"|\".join(case_samples), \"Control_Samples\": \"|\".join(control_samples)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of combinations with support less than 2 in controls: 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_89739/293949802.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cont_combos_w_zero_freq_df[\"Cont_Obs_Count_Combo\"] = cont_combos_w_zero_freq_df.uniq_items.apply(get_counts, args=(apriori_input_controls_df, ))\n",
      "/tmp/ipykernel_89739/293949802.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cont_combos_w_zero_freq_df[\"Cont_Obs_Prob_Combo\"] = cont_combos_w_zero_freq_df['Cont_Obs_Count_Combo'] / number_of_controls\n",
      "/tmp/ipykernel_89739/293949802.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  cont_combos_w_zero_freq_df['Cont_pvalue_more'] = cont_combos_w_zero_freq_df.apply(lambda row: binomtest(int(row['Cont_Obs_Count_Combo']), number_of_controls, row['Cont_Exp_Prob_Combo'], alternative='greater').pvalue, axis=1)\n",
      "/tmp/ipykernel_89739/293949802.py:26: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_sig_case_cont_freqitems_df['Case_Exp_Count_Combo'] = round((all_sig_case_cont_freqitems_df['Case_Exp_Prob_Combo'] * number_of_cases), 2)\n",
      "/tmp/ipykernel_89739/293949802.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_sig_case_cont_freqitems_df['Cont_Exp_Count_Combo'] = round((all_sig_case_cont_freqitems_df['Cont_Exp_Prob_Combo'] * number_of_controls), 2)\n",
      "/tmp/ipykernel_89739/293949802.py:30: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_sig_case_cont_freqitems_df['Effect_Size'] = all_sig_case_cont_freqitems_df.apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of significant combinations that meet the power threshold is 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_89739/293949802.py:35: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_sig_case_cont_freqitems_df['Power_One_Pct'] = round(all_sig_case_cont_freqitems_df.apply(\n",
      "/tmp/ipykernel_89739/293949802.py:40: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  all_sig_case_cont_freqitems_df['Power_Five_Pct'] = round(all_sig_case_cont_freqitems_df.apply(\n"
     ]
    }
   ],
   "source": [
    "###################\n",
    "# Post processing #\n",
    "###################\n",
    "\n",
    "# Check if there is at least a single significant combination after multiple testing correction\n",
    "if multtest_sig_comb_count > 0:\n",
    "    # Check if zero frequency cases exist in controls\n",
    "    cont_combos_w_zero_freq_df = all_sig_case_cont_freqitems_df.loc[all_sig_case_cont_freqitems_df[\"Cont_Obs_Count_Combo\"] == 0]\n",
    "    zero_freq_combo_count = cont_combos_w_zero_freq_df.shape[0]\n",
    "    print('Number of combinations with support less than 2 in controls:', zero_freq_combo_count)\n",
    "\n",
    "    if zero_freq_combo_count > 0:\n",
    "        # REFINE CONTROL FREQUENCIES\n",
    "        # for the zero frequency combos in controls, get their actual combo size\n",
    "        cont_combos_w_zero_freq_df[\"Cont_Obs_Count_Combo\"] = cont_combos_w_zero_freq_df.uniq_items.apply(get_counts, args=(apriori_input_controls_df, ))\n",
    "        cont_combos_w_zero_freq_df[\"Cont_Obs_Prob_Combo\"] = cont_combos_w_zero_freq_df['Cont_Obs_Count_Combo'] / number_of_controls\n",
    "        cont_combos_w_zero_freq_df['Cont_pvalue_more'] = cont_combos_w_zero_freq_df.apply(lambda row: binomtest(int(row['Cont_Obs_Count_Combo']), number_of_controls, row['Cont_Exp_Prob_Combo'], alternative='greater').pvalue, axis=1)\n",
    "        # rewrite the items in the main df\n",
    "        all_sig_case_cont_freqitems_df.update(cont_combos_w_zero_freq_df)\n",
    "    else:\n",
    "        print(\"there are no combinations with zero frequency count in controls\")\n",
    "    \n",
    "    ######################\n",
    "    # POWER CALCULATIONS #\n",
    "    ######################\n",
    "    all_sig_case_cont_freqitems_df['Case_Exp_Count_Combo'] = round((all_sig_case_cont_freqitems_df['Case_Exp_Prob_Combo'] * number_of_cases), 2)\n",
    "    all_sig_case_cont_freqitems_df['Cont_Exp_Count_Combo'] = round((all_sig_case_cont_freqitems_df['Cont_Exp_Prob_Combo'] * number_of_controls), 2)\n",
    "\n",
    "\n",
    "    all_sig_case_cont_freqitems_df['Effect_Size'] = all_sig_case_cont_freqitems_df.apply(\n",
    "        lambda row: proportion_effectsize(row['Case_Obs_Prob_Combo'], row['Cont_Obs_Prob_Combo']),\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    all_sig_case_cont_freqitems_df['Power_One_Pct'] = round(all_sig_case_cont_freqitems_df.apply(\n",
    "        lambda row: tt_ind_solve_power(effect_size=row['Effect_Size'], nobs1=number_of_cases, ratio=number_of_controls/number_of_cases, alpha=0.01),\n",
    "        axis=1\n",
    "    ), 3)\n",
    "\n",
    "    all_sig_case_cont_freqitems_df['Power_Five_Pct'] = round(all_sig_case_cont_freqitems_df.apply(\n",
    "        lambda row: tt_ind_solve_power(effect_size=row['Effect_Size'], nobs1=number_of_cases, ratio=number_of_controls/number_of_cases, alpha=0.05),\n",
    "        axis=1\n",
    "    ), 3)\n",
    "\n",
    "    output_sig_case_cont_freqitems_df = all_sig_case_cont_freqitems_df.loc[all_sig_case_cont_freqitems_df.Power_Five_Pct >= min_power_threshold]\n",
    "    \n",
    "    if len(output_sig_case_cont_freqitems_df)>0:\n",
    "        print(f\"Number of significant combinations that meet the power threshold is {len(output_sig_case_cont_freqitems_df)}\")\n",
    "        if sample_names_ind == \"N\":\n",
    "            output_sig_case_cont_freqitems_df[\"Num_tests\"] = number_of_tests\n",
    "        else:\n",
    "            # add case and control samples for each combo\n",
    "            samples_df = boolean_input_df.set_index([\"Sample_Name\", output_column])\n",
    "            samples_df = samples_df.mask(samples_df == 0).stack().reset_index().drop(0, axis=1).rename(columns={\"level_2\": \"Items\"})\n",
    "            output_sig_case_cont_freqitems_df = output_sig_case_cont_freqitems_df.merge(output_sig_case_cont_freqitems_df.apply(get_samples, args=(samples_df, output_column), axis=1), left_index=True, right_index=True)\n",
    "            output_sig_case_cont_freqitems_df['Num_tests'] = number_of_tests\n",
    "    \n",
    "    else:\n",
    "        print(\"No significant combinations that meet the specified power threshold\")\n",
    "        print(\"Returning ONLY the non-significant combinations\")\n",
    "        # add a column for number of tests done\n",
    "        sel_case_cont_freqitems_df['Num_tests'] = number_of_tests\n",
    "\n",
    "else:\n",
    "    print(\"No significant combinations were found after multiple testing correction\")\n",
    "    print(\"Returning ONLY the non-significant combinations\")\n",
    "    # add a column for number of tests done\n",
    "    sel_case_cont_freqitems_df['Num_tests'] = number_of_tests\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Item_1</th>\n",
       "      <th>Item_2</th>\n",
       "      <th>Case_Obs_Count_Combo</th>\n",
       "      <th>Case_Obs_Count_I1</th>\n",
       "      <th>Case_Obs_Count_I2</th>\n",
       "      <th>Case_Exp_Prob_Combo</th>\n",
       "      <th>Case_Obs_Prob_Combo</th>\n",
       "      <th>Case_pvalue_more</th>\n",
       "      <th>uniq_items</th>\n",
       "      <th>Cont_Obs_Count_Combo</th>\n",
       "      <th>...</th>\n",
       "      <th>Case_Adj_Pval_bonf</th>\n",
       "      <th>Case_Adj_Pval_BH</th>\n",
       "      <th>Case_Exp_Count_Combo</th>\n",
       "      <th>Cont_Exp_Count_Combo</th>\n",
       "      <th>Effect_Size</th>\n",
       "      <th>Power_One_Pct</th>\n",
       "      <th>Power_Five_Pct</th>\n",
       "      <th>Case_Samples</th>\n",
       "      <th>Control_Samples</th>\n",
       "      <th>Num_tests</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Input_9</td>\n",
       "      <td>Input_234</td>\n",
       "      <td>6.0</td>\n",
       "      <td>17</td>\n",
       "      <td>165</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>1.092090e-03</td>\n",
       "      <td>Input_234|Input_9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.268654</td>\n",
       "      <td>0.007892</td>\n",
       "      <td>1.13</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0.098255</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.935</td>\n",
       "      <td>Sample_2449|Sample_2458|Sample_2862|Sample_382...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Input_24</td>\n",
       "      <td>Input_294</td>\n",
       "      <td>5.0</td>\n",
       "      <td>57</td>\n",
       "      <td>19</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>9.048240e-05</td>\n",
       "      <td>Input_24|Input_294</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022259</td>\n",
       "      <td>0.001712</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.089688</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.887</td>\n",
       "      <td>Sample_509|Sample_868|Sample_2186|Sample_2360|...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Input_27</td>\n",
       "      <td>Input_269</td>\n",
       "      <td>7.0</td>\n",
       "      <td>34</td>\n",
       "      <td>106</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>7.539108e-04</td>\n",
       "      <td>Input_269|Input_27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.185462</td>\n",
       "      <td>0.006182</td>\n",
       "      <td>1.45</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0.106135</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.963</td>\n",
       "      <td>Sample_702|Sample_1921|Sample_1963|Sample_2269...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Input_29</td>\n",
       "      <td>Input_372</td>\n",
       "      <td>5.0</td>\n",
       "      <td>23</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>2.361539e-04</td>\n",
       "      <td>Input_29|Input_372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058094</td>\n",
       "      <td>0.003417</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.089688</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.887</td>\n",
       "      <td>Sample_7|Sample_370|Sample_399|Sample_2961|Sam...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Input_30</td>\n",
       "      <td>Input_342</td>\n",
       "      <td>8.0</td>\n",
       "      <td>49</td>\n",
       "      <td>121</td>\n",
       "      <td>0.000958</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>3.183206e-03</td>\n",
       "      <td>Input_30|Input_342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783069</td>\n",
       "      <td>0.016661</td>\n",
       "      <td>2.38</td>\n",
       "      <td>1.42</td>\n",
       "      <td>0.113470</td>\n",
       "      <td>0.924</td>\n",
       "      <td>0.980</td>\n",
       "      <td>Sample_389|Sample_1525|Sample_2734|Sample_3040...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Input_348</td>\n",
       "      <td>Input_30</td>\n",
       "      <td>10.0</td>\n",
       "      <td>117</td>\n",
       "      <td>49</td>\n",
       "      <td>0.000926</td>\n",
       "      <td>0.004019</td>\n",
       "      <td>1.445197e-04</td>\n",
       "      <td>Input_30|Input_348</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.035552</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.89</td>\n",
       "      <td>0.070440</td>\n",
       "      <td>0.466</td>\n",
       "      <td>0.702</td>\n",
       "      <td>Sample_247|Sample_868|Sample_1224|Sample_1525|...</td>\n",
       "      <td>Sample_1125|Sample_3073</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Input_30</td>\n",
       "      <td>Input_372</td>\n",
       "      <td>5.0</td>\n",
       "      <td>49</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000459</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>6.327852e-03</td>\n",
       "      <td>Input_30|Input_372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024323</td>\n",
       "      <td>1.14</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.089688</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.887</td>\n",
       "      <td>Sample_1603|Sample_2118|Sample_2734|Sample_449...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Input_33</td>\n",
       "      <td>Input_462</td>\n",
       "      <td>5.0</td>\n",
       "      <td>36</td>\n",
       "      <td>73</td>\n",
       "      <td>0.000425</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>4.586176e-03</td>\n",
       "      <td>Input_33|Input_462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.020574</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.05</td>\n",
       "      <td>0.089688</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.887</td>\n",
       "      <td>Sample_2118|Sample_2838|Sample_3885|Sample_403...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Input_39</td>\n",
       "      <td>Input_300</td>\n",
       "      <td>5.0</td>\n",
       "      <td>35</td>\n",
       "      <td>54</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>1.122807e-03</td>\n",
       "      <td>Input_300|Input_39</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.276211</td>\n",
       "      <td>0.007892</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.089688</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.887</td>\n",
       "      <td>Sample_568|Sample_1392|Sample_3244|Sample_3809...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Input_55</td>\n",
       "      <td>Input_353</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19</td>\n",
       "      <td>14</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>1.060869e-07</td>\n",
       "      <td>Input_353|Input_55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.089688</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.887</td>\n",
       "      <td>Sample_1425|Sample_2118|Sample_2284|Sample_403...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Input_500</td>\n",
       "      <td>Input_60</td>\n",
       "      <td>5.0</td>\n",
       "      <td>84</td>\n",
       "      <td>34</td>\n",
       "      <td>0.000461</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>6.455869e-03</td>\n",
       "      <td>Input_500|Input_60</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024433</td>\n",
       "      <td>1.15</td>\n",
       "      <td>0.83</td>\n",
       "      <td>0.089688</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.887</td>\n",
       "      <td>Sample_270|Sample_921|Sample_1965|Sample_2411|...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>Input_65</td>\n",
       "      <td>Input_153</td>\n",
       "      <td>8.0</td>\n",
       "      <td>80</td>\n",
       "      <td>27</td>\n",
       "      <td>0.000349</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>3.681012e-06</td>\n",
       "      <td>Input_153|Input_65</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000906</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.073563</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.739</td>\n",
       "      <td>Sample_9|Sample_170|Sample_906|Sample_1010|Sam...</td>\n",
       "      <td>Sample_368</td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Input_119</td>\n",
       "      <td>Input_478</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11</td>\n",
       "      <td>152</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>6.535229e-04</td>\n",
       "      <td>Input_119|Input_478</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.160767</td>\n",
       "      <td>0.005742</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.089688</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.887</td>\n",
       "      <td>Sample_1010|Sample_1405|Sample_3799|Sample_473...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>Input_161</td>\n",
       "      <td>Input_234</td>\n",
       "      <td>6.0</td>\n",
       "      <td>19</td>\n",
       "      <td>165</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>1.905305e-03</td>\n",
       "      <td>Input_161|Input_234</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.468705</td>\n",
       "      <td>0.011718</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.57</td>\n",
       "      <td>0.098255</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.935</td>\n",
       "      <td>Sample_970|Sample_1175|Sample_1255|Sample_1306...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>Input_224</td>\n",
       "      <td>Input_256</td>\n",
       "      <td>6.0</td>\n",
       "      <td>77</td>\n",
       "      <td>52</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>6.186712e-03</td>\n",
       "      <td>Input_224|Input_256</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024323</td>\n",
       "      <td>1.61</td>\n",
       "      <td>1.47</td>\n",
       "      <td>0.098255</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.935</td>\n",
       "      <td>Sample_1725|Sample_1943|Sample_3096|Sample_393...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>Input_250</td>\n",
       "      <td>Input_447</td>\n",
       "      <td>6.0</td>\n",
       "      <td>142</td>\n",
       "      <td>32</td>\n",
       "      <td>0.000734</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>1.104879e-02</td>\n",
       "      <td>Input_250|Input_447</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.032357</td>\n",
       "      <td>1.83</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.098255</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.935</td>\n",
       "      <td>Sample_87|Sample_302|Sample_1367|Sample_2998|S...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>Input_250</td>\n",
       "      <td>Input_450</td>\n",
       "      <td>5.0</td>\n",
       "      <td>142</td>\n",
       "      <td>25</td>\n",
       "      <td>0.000573</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>1.530908e-02</td>\n",
       "      <td>Input_250|Input_450</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.043288</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.089688</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.887</td>\n",
       "      <td>Sample_865|Sample_1494|Sample_2566|Sample_4035...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>Input_251</td>\n",
       "      <td>Input_342</td>\n",
       "      <td>5.0</td>\n",
       "      <td>25</td>\n",
       "      <td>121</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>8.147192e-03</td>\n",
       "      <td>Input_251|Input_342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.027663</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.089688</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.887</td>\n",
       "      <td>Sample_982|Sample_2352|Sample_2447|Sample_2904...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Input_294</td>\n",
       "      <td>Input_342</td>\n",
       "      <td>5.0</td>\n",
       "      <td>19</td>\n",
       "      <td>121</td>\n",
       "      <td>0.000371</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>2.615619e-03</td>\n",
       "      <td>Input_294|Input_342</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643442</td>\n",
       "      <td>0.015211</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.089688</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.887</td>\n",
       "      <td>Sample_1465|Sample_2186|Sample_2360|Sample_238...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Input_328</td>\n",
       "      <td>Input_372</td>\n",
       "      <td>6.0</td>\n",
       "      <td>72</td>\n",
       "      <td>58</td>\n",
       "      <td>0.000675</td>\n",
       "      <td>0.002412</td>\n",
       "      <td>7.520220e-03</td>\n",
       "      <td>Input_328|Input_372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.026056</td>\n",
       "      <td>1.68</td>\n",
       "      <td>1.43</td>\n",
       "      <td>0.098255</td>\n",
       "      <td>0.815</td>\n",
       "      <td>0.935</td>\n",
       "      <td>Sample_1176|Sample_1867|Sample_2176|Sample_263...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Input_421</td>\n",
       "      <td>Input_349</td>\n",
       "      <td>5.0</td>\n",
       "      <td>55</td>\n",
       "      <td>24</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.002010</td>\n",
       "      <td>2.250565e-04</td>\n",
       "      <td>Input_349|Input_421</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055364</td>\n",
       "      <td>0.003417</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.089688</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.887</td>\n",
       "      <td>Sample_709|Sample_888|Sample_1805|Sample_1866|...</td>\n",
       "      <td></td>\n",
       "      <td>246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>21 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Item_1     Item_2  Case_Obs_Count_Combo  Case_Obs_Count_I1  \\\n",
       "2      Input_9  Input_234                   6.0                 17   \n",
       "7     Input_24  Input_294                   5.0                 57   \n",
       "16    Input_27  Input_269                   7.0                 34   \n",
       "19    Input_29  Input_372                   5.0                 23   \n",
       "23    Input_30  Input_342                   8.0                 49   \n",
       "24   Input_348   Input_30                  10.0                117   \n",
       "25    Input_30  Input_372                   5.0                 49   \n",
       "30    Input_33  Input_462                   5.0                 36   \n",
       "33    Input_39  Input_300                   5.0                 35   \n",
       "42    Input_55  Input_353                   5.0                 19   \n",
       "45   Input_500   Input_60                   5.0                 84   \n",
       "50    Input_65  Input_153                   8.0                 80   \n",
       "103  Input_119  Input_478                   5.0                 11   \n",
       "129  Input_161  Input_234                   6.0                 19   \n",
       "142  Input_224  Input_256                   6.0                 77   \n",
       "179  Input_250  Input_447                   6.0                142   \n",
       "180  Input_250  Input_450                   5.0                142   \n",
       "183  Input_251  Input_342                   5.0                 25   \n",
       "214  Input_294  Input_342                   5.0                 19   \n",
       "236  Input_328  Input_372                   6.0                 72   \n",
       "273  Input_421  Input_349                   5.0                 55   \n",
       "\n",
       "     Case_Obs_Count_I2  Case_Exp_Prob_Combo  Case_Obs_Prob_Combo  \\\n",
       "2                  165             0.000453             0.002412   \n",
       "7                   19             0.000175             0.002010   \n",
       "16                 106             0.000582             0.002814   \n",
       "19                  58             0.000216             0.002010   \n",
       "23                 121             0.000958             0.003215   \n",
       "24                  49             0.000926             0.004019   \n",
       "25                  58             0.000459             0.002010   \n",
       "30                  73             0.000425             0.002010   \n",
       "33                  54             0.000305             0.002010   \n",
       "42                  14             0.000043             0.002010   \n",
       "45                  34             0.000461             0.002010   \n",
       "50                  27             0.000349             0.003215   \n",
       "103                152             0.000270             0.002010   \n",
       "129                165             0.000506             0.002412   \n",
       "142                 52             0.000647             0.002412   \n",
       "179                 32             0.000734             0.002412   \n",
       "180                 25             0.000573             0.002010   \n",
       "183                121             0.000489             0.002010   \n",
       "214                121             0.000371             0.002010   \n",
       "236                 58             0.000675             0.002412   \n",
       "273                 24             0.000213             0.002010   \n",
       "\n",
       "     Case_pvalue_more           uniq_items  Cont_Obs_Count_Combo  ...  \\\n",
       "2        1.092090e-03    Input_234|Input_9                   0.0  ...   \n",
       "7        9.048240e-05   Input_24|Input_294                   0.0  ...   \n",
       "16       7.539108e-04   Input_269|Input_27                   0.0  ...   \n",
       "19       2.361539e-04   Input_29|Input_372                   0.0  ...   \n",
       "23       3.183206e-03   Input_30|Input_342                   0.0  ...   \n",
       "24       1.445197e-04   Input_30|Input_348                   2.0  ...   \n",
       "25       6.327852e-03   Input_30|Input_372                   0.0  ...   \n",
       "30       4.586176e-03   Input_33|Input_462                   0.0  ...   \n",
       "33       1.122807e-03   Input_300|Input_39                   0.0  ...   \n",
       "42       1.060869e-07   Input_353|Input_55                   0.0  ...   \n",
       "45       6.455869e-03   Input_500|Input_60                   0.0  ...   \n",
       "50       3.681012e-06   Input_153|Input_65                   1.0  ...   \n",
       "103      6.535229e-04  Input_119|Input_478                   0.0  ...   \n",
       "129      1.905305e-03  Input_161|Input_234                   0.0  ...   \n",
       "142      6.186712e-03  Input_224|Input_256                   0.0  ...   \n",
       "179      1.104879e-02  Input_250|Input_447                   0.0  ...   \n",
       "180      1.530908e-02  Input_250|Input_450                   0.0  ...   \n",
       "183      8.147192e-03  Input_251|Input_342                   0.0  ...   \n",
       "214      2.615619e-03  Input_294|Input_342                   0.0  ...   \n",
       "236      7.520220e-03  Input_328|Input_372                   0.0  ...   \n",
       "273      2.250565e-04  Input_349|Input_421                   0.0  ...   \n",
       "\n",
       "     Case_Adj_Pval_bonf  Case_Adj_Pval_BH  Case_Exp_Count_Combo  \\\n",
       "2              0.268654          0.007892                  1.13   \n",
       "7              0.022259          0.001712                  0.44   \n",
       "16             0.185462          0.006182                  1.45   \n",
       "19             0.058094          0.003417                  0.54   \n",
       "23             0.783069          0.016661                  2.38   \n",
       "24             0.035552          0.002539                  2.30   \n",
       "25             1.000000          0.024323                  1.14   \n",
       "30             1.000000          0.020574                  1.06   \n",
       "33             0.276211          0.007892                  0.76   \n",
       "42             0.000026          0.000013                  0.11   \n",
       "45             1.000000          0.024433                  1.15   \n",
       "50             0.000906          0.000181                  0.87   \n",
       "103            0.160767          0.005742                  0.67   \n",
       "129            0.468705          0.011718                  1.26   \n",
       "142            1.000000          0.024323                  1.61   \n",
       "179            1.000000          0.032357                  1.83   \n",
       "180            1.000000          0.043288                  1.43   \n",
       "183            1.000000          0.027663                  1.22   \n",
       "214            0.643442          0.015211                  0.92   \n",
       "236            1.000000          0.026056                  1.68   \n",
       "273            0.055364          0.003417                  0.53   \n",
       "\n",
       "     Cont_Exp_Count_Combo  Effect_Size  Power_One_Pct  Power_Five_Pct  \\\n",
       "2                    1.50     0.098255          0.815           0.935   \n",
       "7                    0.25     0.089688          0.724           0.887   \n",
       "16                   2.25     0.106135          0.880           0.963   \n",
       "19                   0.42     0.089688          0.724           0.887   \n",
       "23                   1.42     0.113470          0.924           0.980   \n",
       "24                   1.89     0.070440          0.466           0.702   \n",
       "25                   0.80     0.089688          0.724           0.887   \n",
       "30                   1.05     0.089688          0.724           0.887   \n",
       "33                   0.52     0.089688          0.724           0.887   \n",
       "42                   0.07     0.089688          0.724           0.887   \n",
       "45                   0.83     0.089688          0.724           0.887   \n",
       "50                   0.90     0.073563          0.510           0.739   \n",
       "103                  0.37     0.089688          0.724           0.887   \n",
       "129                  1.57     0.098255          0.815           0.935   \n",
       "142                  1.47     0.098255          0.815           0.935   \n",
       "179                  1.16     0.098255          0.815           0.935   \n",
       "180                  0.63     0.089688          0.724           0.887   \n",
       "183                  0.86     0.089688          0.724           0.887   \n",
       "214                  0.49     0.089688          0.724           0.887   \n",
       "236                  1.43     0.098255          0.815           0.935   \n",
       "273                  0.38     0.089688          0.724           0.887   \n",
       "\n",
       "                                          Case_Samples  \\\n",
       "2    Sample_2449|Sample_2458|Sample_2862|Sample_382...   \n",
       "7    Sample_509|Sample_868|Sample_2186|Sample_2360|...   \n",
       "16   Sample_702|Sample_1921|Sample_1963|Sample_2269...   \n",
       "19   Sample_7|Sample_370|Sample_399|Sample_2961|Sam...   \n",
       "23   Sample_389|Sample_1525|Sample_2734|Sample_3040...   \n",
       "24   Sample_247|Sample_868|Sample_1224|Sample_1525|...   \n",
       "25   Sample_1603|Sample_2118|Sample_2734|Sample_449...   \n",
       "30   Sample_2118|Sample_2838|Sample_3885|Sample_403...   \n",
       "33   Sample_568|Sample_1392|Sample_3244|Sample_3809...   \n",
       "42   Sample_1425|Sample_2118|Sample_2284|Sample_403...   \n",
       "45   Sample_270|Sample_921|Sample_1965|Sample_2411|...   \n",
       "50   Sample_9|Sample_170|Sample_906|Sample_1010|Sam...   \n",
       "103  Sample_1010|Sample_1405|Sample_3799|Sample_473...   \n",
       "129  Sample_970|Sample_1175|Sample_1255|Sample_1306...   \n",
       "142  Sample_1725|Sample_1943|Sample_3096|Sample_393...   \n",
       "179  Sample_87|Sample_302|Sample_1367|Sample_2998|S...   \n",
       "180  Sample_865|Sample_1494|Sample_2566|Sample_4035...   \n",
       "183  Sample_982|Sample_2352|Sample_2447|Sample_2904...   \n",
       "214  Sample_1465|Sample_2186|Sample_2360|Sample_238...   \n",
       "236  Sample_1176|Sample_1867|Sample_2176|Sample_263...   \n",
       "273  Sample_709|Sample_888|Sample_1805|Sample_1866|...   \n",
       "\n",
       "             Control_Samples  Num_tests  \n",
       "2                                   246  \n",
       "7                                   246  \n",
       "16                                  246  \n",
       "19                                  246  \n",
       "23                                  246  \n",
       "24   Sample_1125|Sample_3073        246  \n",
       "25                                  246  \n",
       "30                                  246  \n",
       "33                                  246  \n",
       "42                                  246  \n",
       "45                                  246  \n",
       "50                Sample_368        246  \n",
       "103                                 246  \n",
       "129                                 246  \n",
       "142                                 246  \n",
       "179                                 246  \n",
       "180                                 246  \n",
       "183                                 246  \n",
       "214                                 246  \n",
       "236                                 246  \n",
       "273                                 246  \n",
       "\n",
       "[21 rows x 25 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sig_case_cont_freqitems_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
